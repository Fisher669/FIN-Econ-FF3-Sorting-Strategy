{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor1 = 'free_cash_flow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def process_stock_data(stock_data, columns_to_process):\n",
    "    # 将 trade_month 转换为 datetime\n",
    "    stock_data[\"trade_month\"] = pd.to_datetime(stock_data[\"trade_month\"])\n",
    "    \n",
    "    # 提取季度末数据\n",
    "    stock_data[\"quarter\"] = stock_data[\"trade_month\"].dt.to_period(\"Q\")\n",
    "    \n",
    "    # 创建一个映射：季度 -> 每列的第一个非空值（如 ZSCORE）\n",
    "    for column in columns_to_process:\n",
    "        # We first check if the column exists in the dataset\n",
    "        if column not in stock_data.columns:\n",
    "            print(f\"Warning: Column '{column}' not found in data!\")\n",
    "            continue\n",
    "        \n",
    "        # 对每个 stock_code 进行分组处理\n",
    "        for stock_code, group_data in stock_data.groupby(\"stock_code\"):\n",
    "            # Drop rows with missing values in the column and set 'trade_month' as the index\n",
    "            column_data = group_data.dropna(subset=[column]).set_index(\"trade_month\")\n",
    "            \n",
    "            # Create a mapping for the first non-null value of the column in each quarter\n",
    "            quarter_column_map = column_data.groupby(\"quarter\")[column].first()\n",
    "            \n",
    "            # Map the quarterly values to the group_data frame\n",
    "            stock_data.loc[group_data.index, column] = group_data[\"quarter\"].map(quarter_column_map)\n",
    "            \n",
    "            # Perform forward filling for any missing values in the column\n",
    "            stock_data[column] = stock_data[column].fillna(method=\"ffill\")\n",
    "    \n",
    "    return stock_data\n",
    "\n",
    "# Example usage\n",
    "# columns_to_process = [\"ZSCORE\", \"factor2\", \"factor3\"]  # Add other columns you want to process\n",
    "# processed_data = process_stock_data(stock_data, columns_to_process)\n",
    "path = r\"C:\\Users\\Fisher Man\\OneDrive\\Desktop\\Work Sheet\\Py\\Some Projects\\Fin-Econ\\Project\\FF3\\处理后数据2.0.dta\"\n",
    "panel_data = pd.read_stata(path)\n",
    "panel_data.info()\n",
    "labels = [\"证券代码\",\"交易月份\",\"excess_return\",'市场风险溢价因子流通市值加权','市值因子流通市值加权','账面市值比因子流通市值加权',\"每股企业自由现金流量\",\"EM\"]\n",
    "panel_data = panel_data[labels]\n",
    "panel_data.rename(columns={\n",
    "    '证券代码': 'stock_code',\n",
    "    '交易月份': 'trade_month',\n",
    "    '每股企业自由现金流量': 'free_cash_flow',\n",
    "    # '市净率PB': 'pb_ratio',\n",
    "    # 'return1': 'return',\n",
    "    # 'RiskPremium': 'mkt',\n",
    "    '市场风险溢价因子流通市值加权':'mkt',\n",
    "    '市值因子流通市值加权':'smb',\n",
    "    '账面市值比因子流通市值加权':'hml',\n",
    "    'EM': 'em'\n",
    "    # 'SMB': 'smb',\n",
    "    # 'HML': 'hml'\n",
    "}, inplace=True)\n",
    "indicators = ['free_cash_flow','em']\n",
    "panel_data= process_stock_data(panel_data,indicators)\n",
    "panel_data.to_csv('panel_data.csv',index=False)\n",
    "data = pd.read_csv('panel_data.csv')\n",
    "# data.astype(\"float64\")\n",
    "print(data.info())\n",
    "print(data.head())\n",
    "data = data.dropna(subset='excess_return')  # Drop missing values\n",
    "data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sorting factor\n",
    "# factor1 = 'ZSCORE'  # Sorting factor\n",
    "\n",
    "# Filter outliers for factor1\n",
    "# data = filter_outliers(data, factor1)\n",
    "\n",
    "# Drop missing values\n",
    "# data = data.dropna()\n",
    "print(data.shape)\n",
    "\n",
    "# Initialize containers for results\n",
    "# regression_results = []\n",
    "grouped_data = []\n",
    "\n",
    "# Iterate through each trading_month\n",
    "for trading_month, monthly_data in data.groupby('trade_month'):\n",
    "    # Define the number of groups for sorting\n",
    "    num_groups = 10\n",
    "\n",
    "    # Sort by factor1 and split into groups\n",
    "    monthly_data = monthly_data.sort_values(by=factor1).reset_index(drop=True)\n",
    "    monthly_data['factor1_quantile'] = (np.floor(monthly_data.index / (len(monthly_data) / num_groups)) + 1).astype(int)\n",
    "        # # Sort by factor2 and create quantile groups\n",
    "        # group1 = group1.sort_values(by=factor2).reset_index(drop=True)\n",
    "        # group1['factor2_quantile'] = (np.floor(group1.index / (len(group1) / num_groups)) + 1).astype(int)\n",
    "        \n",
    "        # for q2 in range(1, num_groups + 1):\n",
    "        #     group2 = group1[group1['factor2_quantile'] == q2]\n",
    "        #     print(f\"Trading Month: {trading_month}, Factor1 Quantile: {q1}, Factor2 Quantile: {q2},shape: {group2.shape}\")\n",
    "    for q1 in range(1, num_groups + 1):\n",
    "        group1 = monthly_data[monthly_data['factor1_quantile'] == q1]\n",
    "        # print(f\"Trading Month: {trading_month}, Factor1 Quantile: {q1}, shape: {group1.shape}\")\n",
    "        # group1 = group1.dropna()  # Drop missing values\n",
    "        # print(f\"after dropna, shape: {group1.shape}\")\n",
    "        # group1.to_stata('group1.dta')  # Save the data for this group\n",
    "        # Perform regression\n",
    "        print(group1.head())\n",
    "        y = group1['excess_return'].mean()\n",
    "        mkt = group1['mkt'].mean()\n",
    "        smb = group1['smb'].mean()\n",
    "        hml = group1['hml'].mean()\n",
    "        # X = group1[['mkt', 'smb', 'hml']].mean()\n",
    "        # reg_result = reg_m(y, X)\n",
    "        # print(reg_result.params)\n",
    "        # alpha = reg_result.params['const']  # Get the intercept (alpha)\n",
    "        grouped_data.append(\n",
    "            {\n",
    "                'trading_month': trading_month,\n",
    "                'factor1_quantile': q1,\n",
    "                'avg_excess_return': y,\n",
    "                'mkt': mkt,\n",
    "                'smb': smb,\n",
    "                'hml': hml\n",
    "            }\n",
    "        )\n",
    "        # # Store results for this trading_month and group\n",
    "        # regression_results.append({\n",
    "        #     'trading_month': trading_month,\n",
    "        #     'factor1_quantile': q1,\n",
    "        #     'alpha': alpha\n",
    "        # # })\n",
    "\n",
    "    # Combine the data from the first and last quantiles\n",
    "    first_quantile_data = monthly_data[monthly_data['factor1_quantile'] == 1]\n",
    "    last_quantile_data = monthly_data[monthly_data['factor1_quantile'] == num_groups]\n",
    "    # # 计算均值差异\n",
    "    first_mean = first_quantile_data[['excess_return', 'mkt', 'smb', 'hml']].mean()\n",
    "    last_mean = last_quantile_data[['excess_return', 'mkt', 'smb', 'hml']].mean()\n",
    "    diff = last_mean - first_mean\n",
    "    # 将差异结果添加到 grouped_data\n",
    "    grouped_data.append({\n",
    "        'trading_month': trading_month,\n",
    "        'factor1_quantile': 11,  # 使用 26 表示差异组\n",
    "        # 'factor2_quantile': 26,  # 对于这个特殊组也可以标记\n",
    "        'avg_excess_return': diff['excess_return'],\n",
    "        'mkt': diff['mkt'],\n",
    "        'smb': diff['smb'],\n",
    "        'hml': diff['hml']\n",
    "    })\n",
    "grouped_data_df = pd.DataFrame(grouped_data)\n",
    "grouped_data_df.to_csv('grouped_data.csv', index=False)\n",
    "# Convert results to DataFrame\n",
    "# regression_results_df = pd.DataFrame(regression_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data_df = pd.read_csv('grouped_data.csv')\n",
    "grouped_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "# Perform regression for each factor1_quantile\n",
    "def regress_ff3(group):\n",
    "    y = group['avg_excess_return']\n",
    "    X = group[['mkt', 'smb', 'hml']]\n",
    "    X = sm.add_constant(X)  # Add constant for the intercept\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    return {\n",
    "        \"factor1_quantile\": group['factor1_quantile'].iloc[0],\n",
    "        't-stat (alpha)': model.tvalues['const'],\n",
    "        'p-value (alpha)': model.pvalues['const'],\n",
    "        \"alpha\": model.params['const'],\n",
    "        'p-value (mkt)': model.pvalues['mkt'],\n",
    "        \"mkt_coef\": model.params['mkt'],\n",
    "        'p-value (smb)': model.pvalues['smb'],\n",
    "        \"smb_coef\": model.params['smb'],\n",
    "        'p-value (hml)' : model.pvalues['hml'],\n",
    "        \"hml_coef\": model.params['hml'],\n",
    "        \"r_squared\": model.rsquared\n",
    "    }\n",
    "\n",
    "# Apply regression to each quantile group\n",
    "results = grouped_data_df.groupby('factor1_quantile').apply(regress_ff3).apply(pd.Series)\n",
    "results.to_csv(\"FCF_AT_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
